{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWfbtKhcR6s3"
   },
   "source": [
    "# 00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4ahw0tmT2zy",
    "outputId": "5c1c798d-9e34-41ee-a36a-3f54ad3925b1",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:47.708070Z",
     "start_time": "2025-06-03T02:44:46.004497Z"
    }
   },
   "source": [
    "from psutil import win_service_get #获取 Windows 系统上的服务信息\n",
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  3 10:44:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.40                 Driver Version: 572.40         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   40C    P0             17W /   77W |       0MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVK7saKCdSdC"
   },
   "source": [
    "**Google colab** (Jupyter Notebook  .ipynb)\n",
    "\n",
    "右上角connect先, runtime-change runtime type - GPU<br><br>\n",
    "在code cell - python 中:\n",
    "\n",
    "* !nvidia-smi   监控 NVIDIA GPU 的状态和性\n",
    "* Shift+enter 运行代码\n",
    "* Ctrl MM to turn code cell into text cell\n",
    "<br>\n",
    "\n",
    "在text cell - markdown 中：\n",
    "* ##通常用于创建 Markdown 标题(二级标题)\n",
    "* < br>是换行标签\n",
    "* < hr>是水平分割线 <hr>\n",
    "* < p>创建段落，段落间有较大间距< /p>  \n",
    "<p>这是一个段落</p>\n",
    "* 两个`之间 可以作为代码样式\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozDyxCE_Jtmk",
    "outputId": "f4848fce-1828-44c6-958f-e1c41e62a4dc",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:50.716727Z",
     "start_time": "2025-06-03T02:44:47.753033Z"
    }
   },
   "source": [
    "import torch                       #导入pyTorch库\n",
    "import pandas as pd                #导入Pandas库\n",
    "import numpy as np                 #导入Numpy库\n",
    "import matplotlib.pyplot as plt    #导入Matplotlib库\n",
    "\n",
    "print(torch.__version__)           #打印pyTorch的版本号  cu124是CUDA 12.4"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WApgH1AIeV8a"
   },
   "source": [
    "## Introduction to Tensors 张量\n",
    "\n",
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSN7ZFiDjRPD",
    "outputId": "7244f469-58eb-4197-d01a-a06144fffd47",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:50.759221Z",
     "start_time": "2025-06-03T02:44:50.739533Z"
    }
   },
   "source": [
    "# scalar 标量张量\n",
    "scalar = torch.tensor(7)\n",
    "scalar\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ya0EIN3jkva",
    "outputId": "41e84ceb-565c-4353-dd8b-35fcf3f2cc24",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:50.817224Z",
     "start_time": "2025-06-03T02:44:50.814051Z"
    }
   },
   "source": [
    "scalar.ndim #查看维度，标量是0维"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWx6kdtZmSS1",
    "outputId": "e5350eea-fbbd-4fcd-c58f-d7829655c1c1",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:50.884741Z",
     "start_time": "2025-06-03T02:44:50.881205Z"
    }
   },
   "source": [
    "scalar.item() #将张量转换为 Python int"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RX6HG_pnVrl",
    "outputId": "8fbc5ad7-118c-48d5-c0d1-0f734806e348",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:50.960153Z",
     "start_time": "2025-06-03T02:44:50.955609Z"
    }
   },
   "source": [
    "# Vector 向量\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6TzLHX0nhyE",
    "outputId": "8f472256-9dcc-4fd0-be98-16c0efa66f8e",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.031979Z",
     "start_time": "2025-06-03T02:44:51.028466Z"
    }
   },
   "source": "vector.ndim #闭合方括号]的数量，1维",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieQwuVUJns1-",
    "outputId": "3487a531-2c3e-41e2-b192-b1efa2d68f8d",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.125008Z",
     "start_time": "2025-06-03T02:44:51.121575Z"
    }
   },
   "source": [
    "vector.shape #形状 数的数量"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzFMjW-4n9fa",
    "outputId": "ba9d994e-4991-443e-a9b6-44d08faba3d2",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.204503Z",
     "start_time": "2025-06-03T02:44:51.199169Z"
    }
   },
   "source": [
    "# MATRIX 矩阵\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kMiDLJ0oYSB",
    "outputId": "19aa11e2-a0f4-4519-cead-d6d405a44e5c",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.320828Z",
     "start_time": "2025-06-03T02:44:51.317781Z"
    }
   },
   "source": [
    "MATRIX.ndim #维度，两个],2维"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwYcID88oxQH",
    "outputId": "76d49934-f413-4e3e-d672-3311c1522fa1",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.493873Z",
     "start_time": "2025-06-03T02:44:51.490203Z"
    }
   },
   "source": [
    "MATRIX[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n033kH_3o5uk",
    "outputId": "9471662b-fbb2-47f2-a31e-f4bd4185e33c",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.692334Z",
     "start_time": "2025-06-03T02:44:51.689214Z"
    }
   },
   "source": [
    "MATRIX[1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0weSVp3pU7n",
    "outputId": "024dbeb1-7662-4a4b-990b-372f5ba69c8b",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.773411Z",
     "start_time": "2025-06-03T02:44:51.769874Z"
    }
   },
   "source": "MATRIX.shape   #[]的数量, 数的数量",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRjB2jLupl6a",
    "outputId": "5960eac2-7f5a-45a4-ef99-690bb2bfb89e",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.849701Z",
     "start_time": "2025-06-03T02:44:51.846115Z"
    }
   },
   "source": [
    "# TENSOR 张量\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "TENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6Pet4OUw81V",
    "outputId": "17eb225a-f762-4371-aa7d-adc5d7803e58",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:51.925878Z",
     "start_time": "2025-06-03T02:44:51.922029Z"
    }
   },
   "source": [
    "TENSOR[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCABa04gxHP9",
    "outputId": "33fe0ea3-63de-495e-8111-e10fb74ba01c",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.027881Z",
     "start_time": "2025-06-03T02:44:52.024337Z"
    }
   },
   "source": [
    "TENSOR[0][1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJn1YT84p9Kv",
    "outputId": "5a2e0c99-b84a-4d9b-8515-0d4d32328919",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.185969Z",
     "start_time": "2025-06-03T02:44:52.182940Z"
    }
   },
   "source": [
    "TENSOR.ndim  #3个],但张量可以是任何维度"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRAG42sfqKkm",
    "outputId": "6dd50221-f5bf-4399-a9c8-983e68a4e5aa",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.269032Z",
     "start_time": "2025-06-03T02:44:52.265964Z"
    }
   },
   "source": "TENSOR.shape  #ndim-1开始     [[]]的数量, []的数量，数字的数量",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.339176Z",
     "start_time": "2025-06-03T02:44:52.337461Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzeJ87OBqQbH",
    "outputId": "1c7804de-fcc5-4c74-c096-34ba2fcf9189",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.385747Z",
     "start_time": "2025-06-03T02:44:52.381710Z"
    }
   },
   "source": [
    "ComplexTENSOR = torch.tensor([[[[1,2,3,5],\n",
    "                                [3,6,9,4],\n",
    "                                [2,4,5,3],\n",
    "                                [4,4,4,2],\n",
    "                                [1,1,1,2]],\n",
    "                               [[1,2,3,5],\n",
    "                                [3,6,9,4],\n",
    "                                [2,4,5,3],\n",
    "                                [4,4,4,2],\n",
    "                                [1,1,1,2]]]])\n",
    "ComplexTENSOR"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 3, 5],\n",
       "          [3, 6, 9, 4],\n",
       "          [2, 4, 5, 3],\n",
       "          [4, 4, 4, 2],\n",
       "          [1, 1, 1, 2]],\n",
       "\n",
       "         [[1, 2, 3, 5],\n",
       "          [3, 6, 9, 4],\n",
       "          [2, 4, 5, 3],\n",
       "          [4, 4, 4, 2],\n",
       "          [1, 1, 1, 2]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xn5gtOoyxOZu",
    "outputId": "269d49b5-7694-4140-e511-cf611a274a92",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.453541Z",
     "start_time": "2025-06-03T02:44:52.449915Z"
    }
   },
   "source": [
    "ComplexTENSOR[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 5],\n",
       "         [3, 6, 9, 4],\n",
       "         [2, 4, 5, 3],\n",
       "         [4, 4, 4, 2],\n",
       "         [1, 1, 1, 2]],\n",
       "\n",
       "        [[1, 2, 3, 5],\n",
       "         [3, 6, 9, 4],\n",
       "         [2, 4, 5, 3],\n",
       "         [4, 4, 4, 2],\n",
       "         [1, 1, 1, 2]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1ul9uxFt7dB",
    "outputId": "dcffb881-50fd-405b-9714-97635a2991a9",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.579895Z",
     "start_time": "2025-06-03T02:44:52.576166Z"
    }
   },
   "source": [
    "ComplexTENSOR.ndim  #4个]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rr3vNkCjuU9B",
    "outputId": "e4a8d632-8050-44aa-ff5a-f6f843f9d362",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.675264Z",
     "start_time": "2025-06-03T02:44:52.672067Z"
    }
   },
   "source": "ComplexTENSOR.shape # [[[]]]数量1 [[]]数量2 []数量5  数字数量4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.779133Z",
     "start_time": "2025-06-03T02:44:52.774945Z"
    }
   },
   "cell_type": "code",
   "source": "len(ComplexTENSOR)  # dim = 0 的值",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idpny02Fumrv"
   },
   "source": [
    "scalar, vector 变量名小写 <br>\n",
    "MATRIX, TENSOR 变量名大写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhLTnR3zwWuu"
   },
   "source": [
    "### Random tensors 随机张量\n",
    "\n",
    "随机张量很重要，因为许多神经网络的学习方式是他们从充满随机数的张量开始,\n",
    "然后调整这些随机数以更好地表示数据。<br>\n",
    "`Start with random numbers -> look at data -> update random numbers\n",
    "-> look at data -> update random numbers`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2J9wfafHyBmS",
    "outputId": "df2f54be-739f-4ddd-caf8-49e2e6e808f4",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:52.885785Z",
     "start_time": "2025-06-03T02:44:52.861888Z"
    }
   },
   "source": [
    "# create a random tensor of size/shape ([3,4])  ndim=1+1  3个[]  4个数           [[]]1个\n",
    "random_tensor = torch.rand(3,4) #torch.rand(size=(3,4))同种意思\n",
    "random_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8717, 0.7020, 0.6174, 0.9937],\n",
       "        [0.7497, 0.5658, 0.1219, 0.1366],\n",
       "        [0.1934, 0.2071, 0.3368, 0.9309]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SfYaZ-q0WIX",
    "outputId": "2023897b-c559-4f5a-a33c-ced8afb31aa5",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.123978Z",
     "start_time": "2025-06-03T02:44:53.121109Z"
    }
   },
   "source": [
    "random_tensor.ndim   #]数量"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4Qmu4Or0u0e",
    "outputId": "77f198e7-7a94-48b2-eb83-3211a330498d",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.153205Z",
     "start_time": "2025-06-03T02:44:53.149356Z"
    }
   },
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224))  #颜色通道（RGB)，高度，宽度\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim  #size是2 1 0， ndim=2+1"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZesN8SV3qgX"
   },
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQSG5Eho5lNW",
    "outputId": "64c1a3c8-847e-41cf-b3f0-52f5d80cd3ac",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.239482Z",
     "start_time": "2025-06-03T02:44:53.234867Z"
    }
   },
   "source": [
    "#create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))       #3[]  4         1[[]]\n",
    "zeros"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSYUhzMP5ySS",
    "outputId": "3a4595a9-4053-44c3-deff-ae91dd8d6460",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.345029Z",
     "start_time": "2025-06-03T02:44:53.340515Z"
    }
   },
   "source": [
    "zeros * random_tensor  #mask 掩码-用同一个size的tensor 忽略无效数据"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ni-IUTM-6j1l",
    "outputId": "11615c42-3374-4183-8149-910159159c45",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.490548Z",
     "start_time": "2025-06-03T02:44:53.485922Z"
    }
   },
   "source": [
    "#create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7i0IJ6UU7NwP",
    "outputId": "cc7f5580-5d7f-4475-e0f0-c79b058cf6a0",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.653484Z",
     "start_time": "2025-06-03T02:44:53.650188Z"
    }
   },
   "source": [
    "ones.dtype  #default data type 默认的都是torch.float32  浮点数"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exp4DFZh7Tp7"
   },
   "source": [
    "### create a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiVK0uHb9Yc9",
    "outputId": "66df8b74-f47e-40bd-94ec-5e7bf8a63174",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.801706Z",
     "start_time": "2025-06-03T02:44:53.796484Z"
    }
   },
   "source": [
    "# Use torch.arange()  一个范围的tensor\n",
    "one_to_ten = torch.arange(start=1,end=11,step=1)  #起点(默认0），终于(不包括),步长(默认1)\n",
    "one_to_ten    #start, end, step可省略 1,11,1"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ISyjZqwBBzX",
    "outputId": "96a17201-0863-4021-e361-e416470c6509",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:53.914649Z",
     "start_time": "2025-06-03T02:44:53.910179Z"
    }
   },
   "source": [
    "zero_to_nine = torch.arange(10) #0-9\n",
    "zero_to_nine"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_P8rbJN9drf",
    "outputId": "ed4722ff-da17-4262-dd30-97b688d467ac",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.007649Z",
     "start_time": "2025-06-03T02:44:54.003894Z"
    }
   },
   "source": [
    "# creating tensors-like 相同shape/size的tensor\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvUdLM3A--ac",
    "outputId": "71b21c1f-95d9-4991-a7fc-aa85052c1866",
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.098423Z",
     "start_time": "2025-06-03T02:44:54.092699Z"
    }
   },
   "source": [
    "ones = torch.ones_like(one_to_ten)         # 全1\n",
    "fives = torch.full_like(one_to_ten, 5)   # 全5\n",
    "fives"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor datatypes\n",
    "1. Tensors not right datatypes\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.166847Z",
     "start_time": "2025-06-03T02:44:54.163117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=None,  #what datatype is the tensor (e.g. float32 单精度 or float16 半精度)\n",
    "                               device=None, #what device is your tensor on: cpu, cuda\n",
    "                               requires_grad=False)  #whether or not to track 梯度 gradient 求导\n",
    "float_32_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.243011Z",
     "start_time": "2025-06-03T02:44:54.239728Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor.dtype  #即使明说了是None,也是float32 默认",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.350363Z",
     "start_time": "2025-06-03T02:44:54.344466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) #跟f32一样的3，6，9，但类型变了\n",
    "float_16_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.431047Z",
     "start_time": "2025-06-03T02:44:54.426608Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor * float_16_tensor",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.544751Z",
     "start_time": "2025-06-03T02:44:54.541029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "int_32_tensor = torch.tensor([3,6,9],dtype=torch.int32)\n",
    "int_32_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.638342Z",
     "start_time": "2025-06-03T02:44:54.634371Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor * int_32_tensor    #貌似类型不匹配不会出错，但以后可能会有错",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor datatypes\n",
    "1. Tensors not right datatypes  - `tensor.dtype`\n",
    "2. Tensors not right shape  - `tensor.shape`\n",
    "3. Tensors not on the right device - `tensor.device`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.708732Z",
     "start_time": "2025-06-03T02:44:54.704671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "some_tensor = torch.rand((3,4))  #  3[]  4      1[[]]\n",
    "some_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3670, 0.6466, 0.2021, 0.7364],\n",
       "        [0.2206, 0.5300, 0.1539, 0.2290],\n",
       "        [0.3257, 0.1291, 0.0131, 0.6953]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.824334Z",
     "start_time": "2025-06-03T02:44:54.820594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\") #默认是cpu"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3670, 0.6466, 0.2021, 0.7364],\n",
      "        [0.2206, 0.5300, 0.1539, 0.2290],\n",
      "        [0.3257, 0.1291, 0.0131, 0.6953]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* addition\n",
    "* subtraction\n",
    "* multiplication (element-wise) 元素对元素\n",
    "* division\n",
    "* matrix multiplication\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:54.980588Z",
     "start_time": "2025-06-03T02:44:54.975486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.085675Z",
     "start_time": "2025-06-03T02:44:55.081420Z"
    }
   },
   "cell_type": "code",
   "source": "tensor*10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.175235Z",
     "start_time": "2025-06-03T02:44:55.171670Z"
    }
   },
   "cell_type": "code",
   "source": "tensor",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.267853Z",
     "start_time": "2025-06-03T02:44:55.262729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#减10\n",
    "tensor - 10"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.374957Z",
     "start_time": "2025-06-03T02:44:55.371180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# try out pytorch in-built functions\n",
    "torch.mul(tensor,10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.447631Z",
     "start_time": "2025-06-03T02:44:55.443209Z"
    }
   },
   "cell_type": "code",
   "source": "torch.add(tensor,10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "2种方式在神经网络和深度学习：\n",
    "1. element-wise mult\n",
    "2. matrix mult (dot product)\n",
    "\n",
    "There are two rules that performing matrix multiplcation needs to satisfy:\n",
    "1. The **inner dimensions** must match:          @也是matrixmult\n",
    "* `(3,2) @ (3,2)` wont work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "\n",
    "2.The resulting matrix has the shape of the **outer dimensions**\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.553305Z",
     "start_time": "2025-06-03T02:44:55.545384Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(torch.rand(3,2),torch.rand(2,3))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2101, 0.5276, 0.5585],\n",
       "        [0.2512, 0.7092, 0.8969],\n",
       "        [0.1215, 0.2987, 0.3042]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.628574Z",
     "start_time": "2025-06-03T02:44:55.624773Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(torch.rand(2,3),torch.rand(3,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2099, 0.2375],\n",
       "        [0.7906, 1.0521]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.775827Z",
     "start_time": "2025-06-03T02:44:55.772347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Element-wise\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")              #size(3) 和 size(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:55.930152Z",
     "start_time": "2025-06-03T02:44:55.925171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# matrix multiplication\n",
    "# 1,2,3 dot 1,2,3\n",
    "torch.matmul(tensor,tensor)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.030897Z",
     "start_time": "2025-06-03T02:44:56.025815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "#测量整个代码单元格\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1.34 ms\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.091652Z",
     "start_time": "2025-06-03T02:44:56.086622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 二维张量（3行2列）\n",
    "tensor_2d = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(len(tensor_2d))  # 输出: 3（第一维的大小，即行数）  []个数\n",
    "\n",
    "# 三维张量（批量大小为2，每个包含3行4列）\n",
    "tensor_3d = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]      2[[]] 3[] 4       1[[[]]]\n",
    "print(len(tensor_3d))  # 输出: 2（第一维的大小，即批量大小）[[]]\n",
    "print(tensor_3d) # torch.randn 是生成mean=0,标准差=1,的标准状态分布的随机数"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "tensor([[[ 0.0142,  0.4923,  2.4792, -1.1133],\n",
      "         [-0.7001, -0.5458, -0.8742,  0.0727],\n",
      "         [-1.0107,  1.1202,  0.4385, -0.8558]],\n",
      "\n",
      "        [[-0.1103, -0.4689, -0.9749, -0.6759],\n",
      "         [-0.1575, -0.5357, -2.1677, -0.5128],\n",
      "         [-0.4288,  0.7489, -0.7389, -1.6485]]])\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.201476Z",
     "start_time": "2025-06-03T02:44:56.197508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)  #完全更快"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 71 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.300827Z",
     "start_time": "2025-06-03T02:44:56.296527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "B = torch.tensor([[7, 8],\n",
    "                  [9, 10],\n",
    "                  [11,12]])  # 形状: [3, 2]\n",
    "'''\n",
    "1,2,3 dot 7,9,11\n",
    "1,2,3 dot 8,10,12\n",
    "4,5,6 dot 7,9,11\n",
    "4,5,6 dot 8,10,12\n",
    "'''\n",
    "\n",
    "# 矩阵乘法\n",
    "C = torch.matmul(A, B)\n",
    "print(C)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 58,  64],\n",
      "        [139, 154]])\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.393999Z",
     "start_time": "2025-06-03T02:44:56.389019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建两个二维矩阵\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]])  # 形状: [2, 2]\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]])  # 形状: [2, 2]\n",
    "\n",
    "# 矩阵乘法\n",
    "C = torch.matmul(A, B)\n",
    "\n",
    "'''\n",
    "1,2 dot 5,7 = 19\n",
    "1,2 dot 6,8 = 22\n",
    "3,4 dot 5,7 = 15+28=43\n",
    "3,4 dot 6,8 = 18+32=50\n",
    "'''\n",
    "print(C)\n",
    "# 输出:\n",
    "# tensor([[19, 22],\n",
    "#         [43, 50]])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.477947Z",
     "start_time": "2025-06-03T02:44:56.473136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]])  # 形状: [2, 2]\n",
    "v = torch.tensor([5, 6])            # 形状: [2]（一维向量）\n",
    "\n",
    "# 矩阵乘向量\n",
    "w = A @ v\n",
    "'''\n",
    "1,2 dot 5,6 = 5+12=17\n",
    "3,4 dot 5,6 = 15+24=39\n",
    "'''\n",
    "print(w)\n",
    "# 输出:\n",
    "# tensor([17, 39])   #shape [2]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17, 39])\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### one of the most common errors in deep learning : shape errors"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.545271Z",
     "start_time": "2025-06-03T02:44:56.541304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])   #shape 3,2\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])  #shape 3,2\n",
    "\n",
    "# torch.mm(tensor_A, tensor_B)   #mm也是matmul\n",
    "\n",
    "#但是这里无法矩阵乘法， 3by2 x 3by2"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用transpose 转置/维度交换 来改变一个张量的形状"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.607474Z",
     "start_time": "2025-06-03T02:44:56.603433Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_B, tensor_B.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.712921Z",
     "start_time": "2025-06-03T02:44:56.707207Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_B.T,tensor_B.T.shape  #转置后的B",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.806870Z",
     "start_time": "2025-06-03T02:44:56.802757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = torch.matmul(tensor_A,tensor_B.T)\n",
    "output, output.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 27,  30,  33],\n",
       "         [ 61,  68,  75],\n",
       "         [ 95, 106, 117]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:56.903701Z",
     "start_time": "2025-06-03T02:44:56.900224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#                 tensor 交换的两个维度的索引（从 0 开始）\n",
    "# torch.transpose(input, dim0, dim1)\n",
    "\n",
    "                                        #index    0  1         #ndim 2\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 形状: [2, 3]\n",
    "y = torch.transpose(x, 0, 1)  # 交换维度0和1\n",
    "# 等价于 y = x.transpose(0, 1) 或 y = x.T（仅适用于二维张量，两个]]）\n",
    "\n",
    "print(f\"原始形状: {x.shape}\")  # 输出: torch.Size([2, 3])\n",
    "print(f\"转置后形状: {y.shape}\")  # 输出: torch.Size([3, 2])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3])\n",
      "转置后形状: torch.Size([3, 2])\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.003737Z",
     "start_time": "2025-06-03T02:44:57.000546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]\n",
    "\n",
    "# 交换维度1和2    index1,2\n",
    "y = torch.transpose(x, 1, 2)  # 形状变为 [2, 4, 3]\n",
    "\n",
    "print(f\"原始形状: {x.shape}\")  # 输出: torch.Size([2, 3, 4])\n",
    "print(f\"转置后形状: {y.shape}\")  # 输出: torch.Size([2, 4, 3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3, 4])\n",
      "转置后形状: torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor Aggregation 张量聚合\n",
    "Find the min, max, mean 平均值, sum, etc."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.099334Z",
     "start_time": "2025-06-03T02:44:57.095782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.175357Z",
     "start_time": "2025-06-03T02:44:57.170828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.259928Z",
     "start_time": "2025-06-03T02:44:57.255456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.360027Z",
     "start_time": "2025-06-03T02:44:57.355225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the mean   这里int64即long会报错求平均值，转为其他dtype\n",
    "torch.mean(x.type(torch.float32)),  x.type(torch.float32).mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.468724Z",
     "start_time": "2025-06-03T02:44:57.464184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finding the positional min and max 最小/大值所在的index"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.536782Z",
     "start_time": "2025-06-03T02:44:57.533286Z"
    }
   },
   "cell_type": "code",
   "source": "x",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.628532Z",
     "start_time": "2025-06-03T02:44:57.623525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#最小值index - argmin\n",
    "x.argmin()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.715843Z",
     "start_time": "2025-06-03T02:44:57.712395Z"
    }
   },
   "cell_type": "code",
   "source": "x[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.825957Z",
     "start_time": "2025-06-03T02:44:57.821992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#最小值index - argmax\n",
    "x.argmax()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:57.916478Z",
     "start_time": "2025-06-03T02:44:57.913102Z"
    }
   },
   "cell_type": "code",
   "source": "x[9]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reshaping 重塑,stacking 堆叠\n",
    "## squeezing 压缩 and unsqueezing 扩展 tensors\n",
    "* reshaping - 改变张量的形状\n",
    "* view - 返回张量的视图\n",
    "* stacking - 合并多个张量  竖直vstack 水平hstack\n",
    "* squeeze - 去除张量的所有1维\n",
    "* unsqueeze - 给张量加上1维\n",
    "* permute - 返回一个维度排列被置换的输入的视图"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.001387Z",
     "start_time": "2025-06-03T02:44:57.997389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.097043Z",
     "start_time": "2025-06-03T02:44:58.092158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# reshape, 加上1维, 多了1个[]在外面， 元素量要匹配 reshape 1,7 不行 1*7=7\n",
    "#                                                   2,9 不行 2*9=18\n",
    "\n",
    "#[1,9]    1[] 9    1[[]]\n",
    "\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.191381Z",
     "start_time": "2025-06-03T02:44:58.186872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_reshaped = x.reshape(9,1)       # 9[] 1        1[[]]\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.281813Z",
     "start_time": "2025-06-03T02:44:58.277790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# change the view视图, 视图和原张量共享一块内存，跟reshape很像\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.349859Z",
     "start_time": "2025-06-03T02:44:58.345086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "\n",
    "[[1., 2., 3., 4., 5., 6., 7., 8., 9.]]\n",
    "shape[1,9]\n",
    "\n",
    ": 全选  dim=0         []内\n",
    "0     dim=1      index0  1.\n",
    "                    [1.]\n",
    "\n",
    "'''\n",
    "\n",
    "print(z[:, 0])  #tensor([1.])   , shape [1]\n",
    "#改z也会改x，把[]内的数改成5，x也会跟着改\n",
    "z[:, 0] = 5\n",
    "z, x"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.476411Z",
     "start_time": "2025-06-03T02:44:58.471407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x shape [9]\n",
    "# stack tensors on top of each other 张量堆叠               4在dim0\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0)  #堆叠4个x  36个数  [4,9]\n",
    "x_stacked, x_stacked.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.565624Z",
     "start_time": "2025-06-03T02:44:58.561213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=1)  #重新排列后堆叠 [9,4] 4在dim1\n",
    "x_stacked, x_stacked.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [9., 9., 9., 9.]]),\n",
       " torch.Size([9, 4]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.672465Z",
     "start_time": "2025-06-03T02:44:58.668962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "\n",
    "原始形状          [9]\n",
    "dim = 0         [4,9]   4在index0\n",
    "      1         [9,4]   4在index1\n",
    "\n",
    "\n",
    "如果是shape    [2,3]\n",
    "dim=0：在最前面插入新维度，结果形状为 [4, 2, 3]。  4在index 0 = dim0\n",
    "dim=1：在中间插入新维度，结果形状为 [2, 4, 3]。\n",
    "dim=2：在最后插入新维度，结果形状为 [2, 3, 4]。\n",
    "'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n原始形状          [9]\\ndim = 0         [4,9]   4在index0\\n      1         [9,4]   4在index1\\n\\n\\n如果是shape    [2,3]\\ndim=0：在最前面插入新维度，结果形状为 [4, 2, 3]。  4在index 0 = dim0\\ndim=1：在中间插入新维度，结果形状为 [2, 4, 3]。\\ndim=2：在最后插入新维度，结果形状为 [2, 3, 4]。\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.743705Z",
     "start_time": "2025-06-03T02:44:58.739969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  #shape    [2,3]\n",
    "\n",
    "# 在第0维（新维度）上堆叠4个x\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) #[4,2,3]\n",
    "\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)\n",
    "# 输出:"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.841343Z",
     "start_time": "2025-06-03T02:44:58.830237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6]]]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:58.931267Z",
     "start_time": "2025-06-03T02:44:58.928181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=2)\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 1, 1, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[4, 4, 4, 4],\n",
      "         [5, 5, 5, 5],\n",
      "         [6, 6, 6, 6]]]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hstack, Vstack 水平/竖直堆叠"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.046904Z",
     "start_time": "2025-06-03T02:44:59.041798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "b = torch.tensor([[7, 8, 9],\n",
    "                  [10, 11, 12]])  # 形状: [2, 3]\n",
    "\n",
    "hstacked = torch.hstack([a, b])   # 等价于 torch.cat([a, b], dim=1)\n",
    "hstacked, hstacked.shape         #[2,3+3] 水平堆，横着的数字多"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  7,  8,  9],\n",
       "         [ 4,  5,  6, 10, 11, 12]]),\n",
       " torch.Size([2, 6]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.179836Z",
     "start_time": "2025-06-03T02:44:59.175473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vstacked = torch.vstack([a, b]) #等价于torch.cat([a, b], dim=0)\n",
    "vstacked, vstacked.shape       #[2+2,3] 竖直堆，纵向的[]多"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "与 stack 的对比 <br>\n",
    "hstack/vstack：在现有维度上拼接，不增加新维度。<br>\n",
    "torch.stack()：在新维度上堆叠，增加维度数"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Squeeze 压缩"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.274173Z",
     "start_time": "2025-06-03T02:44:59.269160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.squeeze() - 去除张量的所有1维\n",
    "x = torch.randn(1,3,1,224,224)  #形状[1, 3, 1, 224, 224]\n",
    "x_squeezed = torch.squeeze(x)\n",
    "x_squeezed.shape    #torch.Size([3, 224, 224])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.371874Z",
     "start_time": "2025-06-03T02:44:59.367823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [1, 5] 的张量\n",
    "y = torch.randn(1, 5)  # 形状: [1, 5]\n",
    "\n",
    "# 仅移除第0维（大小为1）\n",
    "y_squeezed_0 = torch.squeeze(y, dim=0)  # 形状: [5]\n",
    "\n",
    "# 尝试移除第1维（大小为5不是1，不移除）\n",
    "y_squeezed_1 = torch.squeeze(y, dim=1)  # 形状: [1, 5]（不变）\n",
    "\n",
    "print(\"移除第0维:\", y_squeezed_0.shape)  # 输出: torch.Size([5])\n",
    "print(\"移除第1维:\", y_squeezed_1.shape)  # 输出: torch.Size([1, 5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除第0维: torch.Size([5])\n",
      "移除第1维: torch.Size([1, 5])\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.449913Z",
     "start_time": "2025-06-03T02:44:59.445993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "#remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\"\n",
    "      f\"\\nNew shape: {x_squeezed.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Previous shape: torch.Size([9, 1])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unsqueeze 扩展"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.542673Z",
     "start_time": "2025-06-03T02:44:59.538202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [3, 4] 的张量\n",
    "x = torch.randn(3, 4)  # 形状: [3, 4]\n",
    "\n",
    "# 在第0维前插入一个维度   dim0放1\n",
    "x_unsqueezed_0 = torch.unsqueeze(x, dim=0)  # 形状: [1, 3, 4]\n",
    "\n",
    "# 在第1维前插入一个维度\n",
    "x_unsqueezed_1 = torch.unsqueeze(x, dim=1)  # 形状: [3, 1, 4]\n",
    "\n",
    "# 在最后一维后插入一个维度（等价于 dim=2）\n",
    "x_unsqueezed_2 = torch.unsqueeze(x, dim=-1)  # 形状: [3, 4, 1]\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([3, 4])\n",
    "print(\"插入第0维:\", x_unsqueezed_0.shape)  # 输出: torch.Size([1, 3, 4])\n",
    "print(\"插入第1维:\", x_unsqueezed_1.shape)  # 输出: torch.Size([3, 1, 4])\n",
    "print(\"插入最后一维:\", x_unsqueezed_2.shape)  # 输出: torch.Size([3, 4, 1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([3, 4])\n",
      "插入第0维: torch.Size([1, 3, 4])\n",
      "插入第1维: torch.Size([3, 1, 4])\n",
      "插入最后一维: torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.638259Z",
     "start_time": "2025-06-03T02:44:59.634100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "#加上1维\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.722215Z",
     "start_time": "2025-06-03T02:44:59.718120Z"
    }
   },
   "cell_type": "code",
   "source": "x_reshaped.squeeze()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Permute 重新排序维度, 也是一种视图，共享内存\n",
    "示例 1：二维矩阵转置（等价于 transpose）"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.828724Z",
     "start_time": "2025-06-03T02:44:59.824347Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # 创建一个2x3的矩阵\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "\n",
    "# 使用 permute 实现转置（交换维度0和1）  [3,2]\n",
    "x_permuted = torch.permute(x, (1, 0))  # 等价于 x.transpose(0, 1)\n",
    "\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([2, 3])\n",
    "print(\"转置后形状:\", x_permuted.shape)  # 输出: torch.Size([3, 2])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3])\n",
      "转置后形状: torch.Size([3, 2])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "示例 2：三维张量维度重排"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:44:59.916466Z",
     "start_time": "2025-06-03T02:44:59.912890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [2, 3, 4] 的三维张量\n",
    "x = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]\n",
    "\n",
    "# 重新排列维度为                    [4, 2, 3]\n",
    "x_permuted = torch.permute(x, (2, 0, 1))\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([2, 3, 4])\n",
    "print(\"重排后形状:\", x_permuted.shape)  # 输出: torch.Size([4, 2, 3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3, 4])\n",
      "重排后形状: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.008934Z",
     "start_time": "2025-06-03T02:45:00.004328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#图像数据\n",
    "x_original = torch.rand(size = (224,224,3))   #高度，宽度，颜色通道\n",
    "\n",
    "#Permute the original tensor to 重排维度\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.103326Z",
     "start_time": "2025-06-03T02:45:00.098996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "                              #torch.Size([224, 224, 3])\n",
    "x_original[0,0,0]         #等价于x_original[0][0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1391)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.205211Z",
     "start_time": "2025-06-03T02:45:00.200620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_original[0,0,0]  = 72818\n",
    "x_original[0,0,0], x_permuted[0,0,0]    #也被改了，因为也是view"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(72818.), tensor(72818.))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## indexing (selecting data from tensors)\n",
    "Indexing with PyTorch is similar to indexing with Numpy"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.319764Z",
     "start_time": "2025-06-03T02:45:00.315852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create a tensor\n",
    "import torch\n",
    "x = torch.arange(1,10).reshape(1,3,3)  #9个值 1*3*3\n",
    "x, x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.412032Z",
     "start_time": "2025-06-03T02:45:00.407691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on our new tensor\n",
    "x[0], x[0].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.522981Z",
     "start_time": "2025-06-03T02:45:00.518683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on the middle bracket (dim=1)  [1, 3, 3]的3行\n",
    "x[0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.604511Z",
     "start_time": "2025-06-03T02:45:00.600758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on the most inner bracket (last dimension)\n",
    "x[0][2][2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.690535Z",
     "start_time": "2025-06-03T02:45:00.686448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You can also \":\" to select \"all\" of a target dimension\n",
    "'''\n",
    "第0维  dim0\n",
    "\n",
    "[1,3,3]\n",
    "第0维 1   [[]]\n",
    "第1维 3    []\n",
    "第2维 3\n",
    "\n",
    "                ([[[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]]])\n",
    "x[:, 0]\n",
    ":   第0维中所有元素       [[]]               ---从这里开始算上[]\n",
    "0   第1维中index 0的     index0的[1,2,3]\n",
    "                合体后结果:  [[1,2,3]]\n",
    "'''\n",
    "x[:,0],x[:,0].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.788455Z",
     "start_time": "2025-06-03T02:45:00.783912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#获取所有0维和1维的值，但只获取2维的index1\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "        :  [[]]            ---从这里开始算上[]\n",
    "        :   []内            -- 也要\n",
    "        1   index1的数   2,5,8\n",
    "\n",
    "    结果    [[2,5,8]]\n",
    "\n",
    "x[:,:,数]情况下 --  每个:都要算上[]\n",
    "'''\n",
    "x[:,:,1], x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 5, 8]]), torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.873688Z",
     "start_time": "2025-06-03T02:45:00.869797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取dim0的所有值，但只获取1维和2维的index1\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "\n",
    "          dim0   [[]]                --不算\n",
    "          dim1   index1 [4,5,6]内的   --开始算上[]\n",
    "          dim2  index1  5\n",
    "\n",
    "          [5]\n",
    "\n",
    "x[:,数,数]，以这第一个数的维度开始算上[]\n",
    "'''\n",
    "x[:,1,1]        #tensor([5])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:00.973420Z",
     "start_time": "2025-06-03T02:45:00.969305Z"
    }
   },
   "cell_type": "code",
   "source": "x[0,1,1] #这个没有:就很简单  纯数字 tensor(5)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.071959Z",
     "start_time": "2025-06-03T02:45:01.067786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取dim0和dim1的index0,和dim2的所有值\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "          dim0 [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]]\n",
    "         dim1   [1,2,3]     --开始算上[]\n",
    "         dim2   所有数字1,2,3\n",
    "\n",
    "         [1,2,3]\n",
    "\n",
    "x[数,数,:]，以第二个数开始算上方括号\n",
    "从内开始合体\n",
    "'''\n",
    "x[0,0,:]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.152712Z",
     "start_time": "2025-06-03T02:45:01.148599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# index on x to return 9 #单个数字简单\n",
    "print(x[0,2,2])\n",
    "\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "        shape [1, 3, 3]\n",
    "\n",
    "        dim0   [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]]\n",
    "        dim1  :   []         --开始算上[]\n",
    "        dim2  2  index2的数3,6,9\n",
    "\n",
    "\n",
    "[数,:,数] - 从:才开始算上方括号\n",
    "[3,6,9]\n",
    "'''\n",
    "#index on x to return 3,6,9  #多个数字不简单，一列的\n",
    "print(x[0,:,2])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([3, 6, 9])\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.262894Z",
     "start_time": "2025-06-03T02:45:01.259199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "法二\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "        shape [1, 3, 3]\n",
    "\n",
    "        dim0  :  [[]]内\n",
    "        dim1  :   []内\n",
    "        dim2  2  index2的数\n",
    "        [[3,6,9]]\n",
    "'''\n",
    "print(x[:,:,2])  #"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pytorch tensors & Numpy\n",
    "\n",
    "Numpy is a popular scientific python numerical computation library.\n",
    "And because of this, pytorch has functionality to interact it.\n",
    "\n",
    "* numpy 转 pytorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* pytorch tensor 转 numpy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.367828Z",
     "start_time": "2025-06-03T02:45:01.362063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)  #转成了张量，转过来是float64\n",
    "array, tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.478454Z",
     "start_time": "2025-06-03T02:45:01.474839Z"
    }
   },
   "cell_type": "code",
   "source": "array.dtype  #默认是64位浮点数",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.590141Z",
     "start_time": "2025-06-03T02:45:01.586709Z"
    }
   },
   "cell_type": "code",
   "source": "torch.arange(1.0, 8.0).dtype    #默认是32位浮点数",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.679988Z",
     "start_time": "2025-06-03T02:45:01.676359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor.dtype"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.771855Z",
     "start_time": "2025-06-03T02:45:01.767811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 改array的值，张量没有变化\n",
    "array = array + 1\n",
    "array,tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.866391Z",
     "start_time": "2025-06-03T02:45:01.861982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_array = tensor.numpy()\n",
    "tensor, numpy_array  #默认32位"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:01.963220Z",
     "start_time": "2025-06-03T02:45:01.958741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 改tensor， numpy_array不会被改变\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_array"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reproducity 可重现性 - 试图消除随机性\n",
    "神经网络学习从随机数开始-tensor operations-update随机数让他们不断更好地呈现-重复重复...\n",
    "\n",
    "为了减少随机性，有个**random seed**的概念，随机种子作用是调整随机性 flavor\n",
    "\n",
    "pseudorandomness 伪随机 p不发音"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:02.053312Z",
     "start_time": "2025-06-03T02:45:02.049329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "#create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)  #不太可能相等"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6997, 0.4303, 0.3186, 0.8669],\n",
      "        [0.6627, 0.3381, 0.2808, 0.1138],\n",
      "        [0.4300, 0.6025, 0.4762, 0.7901]])\n",
      "tensor([[0.7674, 0.2680, 0.2719, 0.8469],\n",
      "        [0.1561, 0.5452, 0.4210, 0.4690],\n",
      "        [0.1284, 0.7827, 0.9455, 0.8577]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:02.166455Z",
     "start_time": "2025-06-03T02:45:02.157388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 让我们做些随机但可重现的张量\n",
    "import torch\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42 #默认是42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)  #每次随机前都要设置下\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Running tensors and pytorch objects on GPUs and 计算地更快\n",
    "\n",
    "GPUs = 更快的数字计算  因为CUDA, NVIDIA,和pytorch背后计算"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "选项\n",
    "1. google Colab\n",
    "2. 自己的GPU\n",
    "3. cloud computing - GCP, AWS, Azure"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check for GPU access with pytorch"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:03.830123Z",
     "start_time": "2025-06-03T02:45:02.249940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for GPU access with pytorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:03.854131Z",
     "start_time": "2025-06-03T02:45:03.850698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup device agnostic code 设备无关性\n",
    "# 自动选择可用的计算设备（GPU 或 CPU）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:03.925437Z",
     "start_time": "2025-06-03T02:45:03.920797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count number of devices\n",
    "torch.cuda.device_count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Putting tensors and models on the GPU\n",
    "\n",
    "The reason we want to put on GPU 因为他快"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:04.013735Z",
     "start_time": "2025-06-03T02:45:04.010666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1,2,3],device=\"cpu\")\n",
    "\n",
    "#不在gpu上\n",
    "print(tensor, tensor.device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:04.881449Z",
     "start_time": "2025-06-03T02:45:04.103216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.Moving tensors back to CPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:04.906939Z",
     "start_time": "2025-06-03T02:45:04.903778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if tensor is on GPU, 不能转换成numpy\n",
    "# tensor_on_gpu.numpy() 会报错！"
   ],
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:04.957093Z",
     "start_time": "2025-06-03T02:45:04.953275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 解决方法 - 设置一个在cpu上的\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:05.040173Z",
     "start_time": "2025-06-03T02:45:05.035960Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_on_gpu #还是在gpu上面",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise & Extracurriculars\n",
    "作业: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb <br>\n",
    "答案：https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "THE END\n",
    "<hr>"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T02:45:05.129444Z",
     "start_time": "2025-06-03T02:45:05.127486Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
