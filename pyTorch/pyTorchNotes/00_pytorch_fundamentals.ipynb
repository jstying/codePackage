{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWfbtKhcR6s3"
   },
   "source": [
    "# 00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4ahw0tmT2zy",
    "outputId": "5c1c798d-9e34-41ee-a36a-3f54ad3925b1",
    "ExecuteTime": {
     "end_time": "2025-05-30T07:40:22.224195Z",
     "start_time": "2025-05-30T07:40:20.560843Z"
    }
   },
   "source": [
    "from psutil import win_service_get #获取 Windows 系统上的服务信息\n",
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 30 15:40:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.40                 Driver Version: 572.40         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P3             16W /   67W |       0MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVK7saKCdSdC"
   },
   "source": [
    "**Google colab** (Jupyter Notebook  .ipynb)\n",
    "\n",
    "右上角connect先, runtime-change runtime type - GPU<br><br>\n",
    "在code cell - python 中:\n",
    "\n",
    "* !nvidia-smi   监控 NVIDIA GPU 的状态和性\n",
    "* Shift+enter 运行代码\n",
    "* Ctrl MM to turn code cell into text cell\n",
    "<br>\n",
    "\n",
    "在text cell - markdown 中：\n",
    "* ##通常用于创建 Markdown 标题(二级标题)\n",
    "* < br>是换行标签\n",
    "* < hr>是水平分割线 <hr>\n",
    "* < p>创建段落，段落间有较大间距< /p>  \n",
    "<p>这是一个段落</p>\n",
    "* 两个`之间 可以作为代码样式\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozDyxCE_Jtmk",
    "outputId": "f4848fce-1828-44c6-958f-e1c41e62a4dc",
    "ExecuteTime": {
     "end_time": "2025-05-30T00:41:36.076070Z",
     "start_time": "2025-05-30T00:41:32.776191Z"
    }
   },
   "source": [
    "import torch                       #导入pyTorch库\n",
    "import pandas as pd                #导入Pandas库\n",
    "import numpy as np                 #导入Numpy库\n",
    "import matplotlib.pyplot as plt    #导入Matplotlib库\n",
    "\n",
    "print(torch.__version__)           #打印pyTorch的版本号  cu124是CUDA 12.4"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WApgH1AIeV8a"
   },
   "source": [
    "## Introduction to Tensors 张量\n",
    "\n",
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSN7ZFiDjRPD",
    "outputId": "7244f469-58eb-4197-d01a-a06144fffd47",
    "ExecuteTime": {
     "end_time": "2025-05-28T08:57:29.675066Z",
     "start_time": "2025-05-28T08:57:29.667936Z"
    }
   },
   "source": [
    "# scalar 标量张量\n",
    "scalar = torch.tensor(7)\n",
    "scalar\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ya0EIN3jkva",
    "outputId": "41e84ceb-565c-4353-dd8b-35fcf3f2cc24",
    "ExecuteTime": {
     "end_time": "2025-05-28T08:50:46.714514Z",
     "start_time": "2025-05-28T08:50:46.710600Z"
    }
   },
   "source": [
    "scalar.ndim #查看维度，标量是0维"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWx6kdtZmSS1",
    "outputId": "e5350eea-fbbd-4fcd-c58f-d7829655c1c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() #将张量转换为 Python int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RX6HG_pnVrl",
    "outputId": "8fbc5ad7-118c-48d5-c0d1-0f734806e348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector 向量\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6TzLHX0nhyE",
    "outputId": "8f472256-9dcc-4fd0-be98-16c0efa66f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "vector.ndim #闭合方括号]的数量，1维"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieQwuVUJns1-",
    "outputId": "3487a531-2c3e-41e2-b192-b1efa2d68f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape #形状 数的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzFMjW-4n9fa",
    "outputId": "ba9d994e-4991-443e-a9b6-44d08faba3d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX 矩阵\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kMiDLJ0oYSB",
    "outputId": "19aa11e2-a0f4-4519-cead-d6d405a44e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim #维度，两个],2维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwYcID88oxQH",
    "outputId": "76d49934-f413-4e3e-d672-3311c1522fa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n033kH_3o5uk",
    "outputId": "9471662b-fbb2-47f2-a31e-f4bd4185e33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0weSVp3pU7n",
    "outputId": "024dbeb1-7662-4a4b-990b-372f5ba69c8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "MATRIX.shape   #[]的数量, 数的数量"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRjB2jLupl6a",
    "outputId": "5960eac2-7f5a-45a4-ef99-690bb2bfb89e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR 张量\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6Pet4OUw81V",
    "outputId": "17eb225a-f762-4371-aa7d-adc5d7803e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCABa04gxHP9",
    "outputId": "33fe0ea3-63de-495e-8111-e10fb74ba01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJn1YT84p9Kv",
    "outputId": "5a2e0c99-b84a-4d9b-8515-0d4d32328919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim  #3个],但张量可以是任何维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRAG42sfqKkm",
    "outputId": "6dd50221-f5bf-4399-a9c8-983e68a4e5aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "TENSOR.shape  #ndim-1开始     [[]]的数量, []的数量，数字的数量"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzeJ87OBqQbH",
    "outputId": "1c7804de-fcc5-4c74-c096-34ba2fcf9189"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 3, 5],\n",
       "          [3, 6, 9, 4],\n",
       "          [2, 4, 5, 3],\n",
       "          [4, 4, 4, 2],\n",
       "          [1, 1, 1, 2]],\n",
       "\n",
       "         [[1, 2, 3, 5],\n",
       "          [3, 6, 9, 4],\n",
       "          [2, 4, 5, 3],\n",
       "          [4, 4, 4, 2],\n",
       "          [1, 1, 1, 2]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComplexTENSOR = torch.tensor([[[[1,2,3,5],\n",
    "                                [3,6,9,4],\n",
    "                                [2,4,5,3],\n",
    "                                [4,4,4,2],\n",
    "                                [1,1,1,2]],\n",
    "                               [[1,2,3,5],\n",
    "                                [3,6,9,4],\n",
    "                                [2,4,5,3],\n",
    "                                [4,4,4,2],\n",
    "                                [1,1,1,2]]]])\n",
    "ComplexTENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xn5gtOoyxOZu",
    "outputId": "269d49b5-7694-4140-e511-cf611a274a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 5],\n",
       "         [3, 6, 9, 4],\n",
       "         [2, 4, 5, 3],\n",
       "         [4, 4, 4, 2],\n",
       "         [1, 1, 1, 2]],\n",
       "\n",
       "        [[1, 2, 3, 5],\n",
       "         [3, 6, 9, 4],\n",
       "         [2, 4, 5, 3],\n",
       "         [4, 4, 4, 2],\n",
       "         [1, 1, 1, 2]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComplexTENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1ul9uxFt7dB",
    "outputId": "dcffb881-50fd-405b-9714-97635a2991a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComplexTENSOR.ndim  #4个]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rr3vNkCjuU9B",
    "outputId": "e4a8d632-8050-44aa-ff5a-f6f843f9d362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "ComplexTENSOR.shape # [[[]]]数量1 [[]]数量2 []数量5  数字数量4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idpny02Fumrv"
   },
   "source": [
    "scalar, vector 变量名小写 <br>\n",
    "MATRIX, TENSOR 变量名大写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhLTnR3zwWuu"
   },
   "source": [
    "### Random tensors 随机张量\n",
    "\n",
    "随机张量很重要，因为许多神经网络的学习方式是他们从充满随机数的张量开始,\n",
    "然后调整这些随机数以更好地表示数据。<br>\n",
    "`Start with random numbers -> look at data -> update random numbers\n",
    "-> look at data -> update random numbers`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2J9wfafHyBmS",
    "outputId": "df2f54be-739f-4ddd-caf8-49e2e6e808f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7731, 0.1257, 0.2882, 0.6766],\n",
       "        [0.1866, 0.2867, 0.4451, 0.8294],\n",
       "        [0.6499, 0.0762, 0.6184, 0.9674]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor of size/shape ([3,4])  ndim=1+1  3个[]  4个数           [[]]1个\n",
    "random_tensor = torch.rand(3,4) #torch.rand(size=(3,4))同种意思\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SfYaZ-q0WIX",
    "outputId": "2023897b-c559-4f5a-a33c-ced8afb31aa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim   #]数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4Qmu4Or0u0e",
    "outputId": "77f198e7-7a94-48b2-eb83-3211a330498d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224))  #颜色通道（RGB)，高度，宽度\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim  #size是2 1 0， ndim=2+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZesN8SV3qgX"
   },
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQSG5Eho5lNW",
    "outputId": "64c1a3c8-847e-41cf-b3f0-52f5d80cd3ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))       #3[]  4         1[[]]\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSYUhzMP5ySS",
    "outputId": "3a4595a9-4053-44c3-deff-ae91dd8d6460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor  #mask 掩码-用同一个size的tensor 忽略无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ni-IUTM-6j1l",
    "outputId": "11615c42-3374-4183-8149-910159159c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7i0IJ6UU7NwP",
    "outputId": "cc7f5580-5d7f-4475-e0f0-c79b058cf6a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype  #default data type 默认的都是torch.float32  浮点数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exp4DFZh7Tp7"
   },
   "source": [
    "### create a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiVK0uHb9Yc9",
    "outputId": "66df8b74-f47e-40bd-94ec-5e7bf8a63174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange()  一个范围的tensor\n",
    "one_to_ten = torch.arange(start=1,end=11,step=1)  #起点(默认0），终于(不包括),步长(默认1)\n",
    "one_to_ten    #start, end, step可省略 1,11,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ISyjZqwBBzX",
    "outputId": "96a17201-0863-4021-e361-e416470c6509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_nine = torch.arange(10) #0-9\n",
    "zero_to_nine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_P8rbJN9drf",
    "outputId": "ed4722ff-da17-4262-dd30-97b688d467ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors-like 相同shape/size的tensor\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvUdLM3A--ac",
    "outputId": "71b21c1f-95d9-4991-a7fc-aa85052c1866"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones_like(one_to_ten)         # 全1\n",
    "fives = torch.full_like(one_to_ten, 5)   # 全5\n",
    "fives"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor datatypes\n",
    "1. Tensors not right datatypes\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:06:47.562351Z",
     "start_time": "2025-05-29T08:06:47.556566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=None,  #what datatype is the tensor (e.g. float32 单精度 or float16 半精度)\n",
    "                               device=None, #what device is your tensor on: cpu, cuda\n",
    "                               requires_grad=False)  #whether or not to track 梯度 gradient 求导\n",
    "float_32_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:00:37.652781Z",
     "start_time": "2025-05-29T08:00:37.648933Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor.dtype  #即使明说了是None,也是float32 默认",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:07:14.281354Z",
     "start_time": "2025-05-29T08:07:14.274948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) #跟f32一样的3，6，9，但类型变了\n",
    "float_16_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:09:56.531133Z",
     "start_time": "2025-05-29T08:09:56.526197Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor * float_16_tensor",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:11:30.690431Z",
     "start_time": "2025-05-29T08:11:30.685235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "int_32_tensor = torch.tensor([3,6,9],dtype=torch.int32)\n",
    "int_32_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:11:50.598614Z",
     "start_time": "2025-05-29T08:11:50.593906Z"
    }
   },
   "cell_type": "code",
   "source": "float_32_tensor * int_32_tensor    #貌似类型不匹配不会出错，但以后可能会有错",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor datatypes\n",
    "1. Tensors not right datatypes  - `tensor.dtype`\n",
    "2. Tensors not right shape  - `tensor.shape`\n",
    "3. Tensors not on the right device - `tensor.device`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:16:34.138188Z",
     "start_time": "2025-05-29T08:16:34.133583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "some_tensor = torch.rand((3,4))  #  3[]  4      1[[]]\n",
    "some_tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4050, 0.3458, 0.8678, 0.6637],\n",
       "        [0.0740, 0.9203, 0.2590, 0.6012],\n",
       "        [0.3108, 0.3027, 0.1994, 0.8277]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T08:19:00.566143Z",
     "start_time": "2025-05-29T08:19:00.562257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\") #默认是cpu"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4050, 0.3458, 0.8678, 0.6637],\n",
      "        [0.0740, 0.9203, 0.2590, 0.6012],\n",
      "        [0.3108, 0.3027, 0.1994, 0.8277]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* addition\n",
    "* subtraction\n",
    "* multiplication (element-wise) 元素对元素\n",
    "* division\n",
    "* matrix multiplication\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:42:49.906142Z",
     "start_time": "2025-05-30T00:42:49.880171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:26:44.656685500Z",
     "start_time": "2025-05-29T08:34:17.299641Z"
    }
   },
   "cell_type": "code",
   "source": "tensor*10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:26:44.659684700Z",
     "start_time": "2025-05-29T08:34:23.627387Z"
    }
   },
   "cell_type": "code",
   "source": "tensor",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:26:44.673827200Z",
     "start_time": "2025-05-29T08:34:42.770787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#减10\n",
    "tensor - 10"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9., -8., -7.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:26:44.694815300Z",
     "start_time": "2025-05-29T08:35:22.925906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# try out pytorch in-built functions\n",
    "torch.mul(tensor,10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:26:44.695815200Z",
     "start_time": "2025-05-29T08:35:32.073992Z"
    }
   },
   "cell_type": "code",
   "source": "torch.add(tensor,10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "2种方式在神经网络和深度学习：\n",
    "1. element-wise mult\n",
    "2. matrix mult (dot product)\n",
    "\n",
    "There are two rules that performing matrix multiplcation needs to satisfy:\n",
    "1. The **inner dimensions** must match:          @也是matrixmult\n",
    "* `(3,2) @ (3,2)` wont work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "\n",
    "2.The resulting matrix has the shape of the **outer dimensions**\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:43:41.633094Z",
     "start_time": "2025-05-30T00:43:41.605028Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(torch.rand(3,2),torch.rand(2,3))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0870, 0.0715, 0.2417],\n",
       "        [0.2116, 0.1884, 0.3470],\n",
       "        [0.1621, 0.1466, 0.2285]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:43:41.671715Z",
     "start_time": "2025-05-30T00:43:41.667798Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(torch.rand(2,3),torch.rand(3,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8306, 1.0496],\n",
       "        [0.9694, 1.0601]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:43:41.978781Z",
     "start_time": "2025-05-30T00:43:41.975331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Element-wise\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")              #size(3) 和 size(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:43:42.429953Z",
     "start_time": "2025-05-30T00:43:42.425383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# matrix multiplication\n",
    "# 1,2,3 dot 1,2,3\n",
    "torch.matmul(tensor,tensor)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:44:27.013781Z",
     "start_time": "2025-05-30T00:44:27.009292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "#测量整个代码单元格\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.52 ms\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:13:03.112499Z",
     "start_time": "2025-05-30T07:13:03.107819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 二维张量（3行2列）\n",
    "tensor_2d = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(len(tensor_2d))  # 输出: 3（第一维的大小，即行数）  []个数\n",
    "\n",
    "# 三维张量（批量大小为2，每个包含3行4列）\n",
    "tensor_3d = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]      2[[]] 3[] 4       1[[[]]]\n",
    "print(len(tensor_3d))  # 输出: 2（第一维的大小，即批量大小）[[]]\n",
    "print(tensor_3d) # torch.randn 是生成mean=0,标准差=1,的标准状态分布的随机数"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "tensor([[[ 1.0661, -0.0306, -1.1709, -0.6065],\n",
      "         [-0.8554, -0.9551,  0.4564,  0.6468],\n",
      "         [-0.7069,  1.5065,  1.3334, -0.5071]],\n",
      "\n",
      "        [[ 2.8094, -0.1971,  0.7987,  0.5144],\n",
      "         [-0.5750,  0.5259,  0.3850,  1.4188],\n",
      "         [-0.2461,  0.1371,  0.3935, -0.2432]]])\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T00:48:08.298538Z",
     "start_time": "2025-05-30T00:48:08.293494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)  #完全更快"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 192 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:07:51.114271Z",
     "start_time": "2025-05-30T01:07:51.110472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "B = torch.tensor([[7, 8],\n",
    "                  [9, 10],\n",
    "                  [11,12]])  # 形状: [3, 2]\n",
    "'''\n",
    "1,2,3 dot 7,9,11\n",
    "1,2,3 dot 8,10,12\n",
    "4,5,6 dot 7,9,11\n",
    "4,5,6 dot 8,10,12\n",
    "'''\n",
    "\n",
    "# 矩阵乘法\n",
    "C = torch.matmul(A, B)\n",
    "print(C)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 58,  64],\n",
      "        [139, 154]])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建两个二维矩阵\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]])  # 形状: [2, 2]\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]])  # 形状: [2, 2]\n",
    "\n",
    "# 矩阵乘法\n",
    "C = torch.matmul(A, B)\n",
    "\n",
    "'''\n",
    "1,2 dot 5,7 = 19\n",
    "1,2 dot 6,8 = 22\n",
    "3,4 dot 5,7 = 15+28=43\n",
    "3,4 dot 6,8 = 18+32=50\n",
    "'''\n",
    "print(C)\n",
    "# 输出:\n",
    "# tensor([[19, 22],\n",
    "#         [43, 50]])"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:14:06.877132Z",
     "start_time": "2025-05-30T01:14:06.871024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]])  # 形状: [2, 2]\n",
    "v = torch.tensor([5, 6])            # 形状: [2]（一维向量）\n",
    "\n",
    "# 矩阵乘向量\n",
    "w = A @ v\n",
    "'''\n",
    "1,2 dot 5,6 = 5+12=17\n",
    "3,4 dot 5,6 = 15+24=39\n",
    "'''\n",
    "print(w)\n",
    "# 输出:\n",
    "# tensor([17, 39])   #shape [2]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17, 39])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### one of the most common errors in deep learning : shape errors"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:16:18.728617Z",
     "start_time": "2025-05-30T01:16:18.725335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])   #shape 3,2\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])  #shape 3,2\n",
    "\n",
    "# torch.mm(tensor_A, tensor_B)   #mm也是matmul\n",
    "\n",
    "#但是这里无法矩阵乘法， 3by2 x 3by2"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用transpose 转置/维度交换 来改变一个张量的形状"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:31:34.568188Z",
     "start_time": "2025-05-30T01:31:34.561899Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_B, tensor_B.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:31:49.257138Z",
     "start_time": "2025-05-30T01:31:49.252365Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_B.T,tensor_B.T.shape  #转置后的B",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:35:36.286786Z",
     "start_time": "2025-05-30T01:35:36.282221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = torch.matmul(tensor_A,tensor_B.T)\n",
    "output, output.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 27,  30,  33],\n",
       "         [ 61,  68,  75],\n",
       "         [ 95, 106, 117]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:24:46.164325Z",
     "start_time": "2025-05-30T01:24:46.159141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#                 tensor 交换的两个维度的索引（从 0 开始）\n",
    "# torch.transpose(input, dim0, dim1)\n",
    "\n",
    "                                        #index    0  1         #ndim 2\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 形状: [2, 3]\n",
    "y = torch.transpose(x, 0, 1)  # 交换维度0和1\n",
    "# 等价于 y = x.transpose(0, 1) 或 y = x.T（仅适用于二维张量，两个]]）\n",
    "\n",
    "print(f\"原始形状: {x.shape}\")  # 输出: torch.Size([2, 3])\n",
    "print(f\"转置后形状: {y.shape}\")  # 输出: torch.Size([3, 2])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3])\n",
      "转置后形状: torch.Size([3, 2])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:25:44.841281Z",
     "start_time": "2025-05-30T01:25:44.837950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]\n",
    "\n",
    "# 交换维度1和2    index1,2\n",
    "y = torch.transpose(x, 1, 2)  # 形状变为 [2, 4, 3]\n",
    "\n",
    "print(f\"原始形状: {x.shape}\")  # 输出: torch.Size([2, 3, 4])\n",
    "print(f\"转置后形状: {y.shape}\")  # 输出: torch.Size([2, 4, 3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3, 4])\n",
      "转置后形状: torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor Aggregation 张量聚合\n",
    "Find the min, max, mean 平均值, sum, etc."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:41:24.531561Z",
     "start_time": "2025-05-30T01:41:24.527205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:39:54.867155Z",
     "start_time": "2025-05-30T01:39:54.863038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:40:34.763568Z",
     "start_time": "2025-05-30T01:40:34.759077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:49:46.159927Z",
     "start_time": "2025-05-30T01:49:46.155415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the mean   这里int64即long会报错求平均值，转为其他dtype\n",
    "torch.mean(x.type(torch.float32)),  x.type(torch.float32).mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:51:02.477375Z",
     "start_time": "2025-05-30T01:51:02.472961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finding the positional min and max 最小/大值所在的index"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:54:25.214384Z",
     "start_time": "2025-05-30T01:54:25.210420Z"
    }
   },
   "cell_type": "code",
   "source": "x",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:54:27.519187Z",
     "start_time": "2025-05-30T01:54:27.515124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#最小值index - argmin\n",
    "x.argmin()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:54:32.806528Z",
     "start_time": "2025-05-30T01:54:32.802321Z"
    }
   },
   "cell_type": "code",
   "source": "x[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:54:56.015606Z",
     "start_time": "2025-05-30T01:54:56.011044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#最小值index - argmax\n",
    "x.argmax()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T01:55:09.553887Z",
     "start_time": "2025-05-30T01:55:09.549310Z"
    }
   },
   "cell_type": "code",
   "source": "x[9]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reshaping 重塑,stacking 堆叠\n",
    "## squeezing 压缩 and unsqueezing 扩展 tensors\n",
    "* reshaping - 改变张量的形状\n",
    "* view - 返回张量的视图\n",
    "* stacking - 合并多个张量  竖直vstack 水平hstack\n",
    "* squeeze - 去除张量的所有1维\n",
    "* unsqueeze - 给张量加上1维\n",
    "* permute - 返回一个维度排列被置换的输入的视图"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:34:16.089468Z",
     "start_time": "2025-05-30T05:34:16.085470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:07:25.985239Z",
     "start_time": "2025-05-30T02:07:25.979465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# reshape, 加上1维, 多了1个[]在外面， 元素量要匹配 reshape 1,7 不行 1*7=7\n",
    "#                                                   2,9 不行 2*9=18\n",
    "\n",
    "#[1,9]    1[] 9    1[[]]\n",
    "\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:07:41.824572Z",
     "start_time": "2025-05-30T02:07:41.820588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_reshaped = x.reshape(9,1)       # 9[] 1        1[[]]\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:34:27.178019Z",
     "start_time": "2025-05-30T05:34:27.173876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# change the view视图, 视图和原张量共享一块内存，跟reshape很像\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:44:13.444436Z",
     "start_time": "2025-05-30T05:44:13.438649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "\n",
    "[[1., 2., 3., 4., 5., 6., 7., 8., 9.]]\n",
    "shape[1,9]\n",
    "\n",
    ": 全选  dim=0         []内\n",
    "0     dim=1      index0  1.\n",
    "                    [1.]\n",
    "\n",
    "'''\n",
    "\n",
    "print(z[:, 0])  #tensor([1.])   , shape [1]\n",
    "#改z也会改x，把[]内的数改成5，x也会跟着改\n",
    "z[:, 0] = 5\n",
    "z, x"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:35:32.236250Z",
     "start_time": "2025-05-30T05:35:32.231292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x shape [9]\n",
    "# stack tensors on top of each other 张量堆叠               4在dim0\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0)  #堆叠4个x  36个数  [4,9]\n",
    "x_stacked, x_stacked.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:29:21.021118Z",
     "start_time": "2025-05-30T02:29:21.015326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=1)  #重新排列后堆叠 [9,4] 4在dim1\n",
    "x_stacked, x_stacked.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [9., 9., 9., 9.]]),\n",
       " torch.Size([9, 4]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "\n",
    "原始形状          [9]\n",
    "dim = 0         [4,9]   4在index0\n",
    "      1         [9,4]   4在index1\n",
    "\n",
    "\n",
    "如果是shape    [2,3]\n",
    "dim=0：在最前面插入新维度，结果形状为 [4, 2, 3]。  4在index 0 = dim0\n",
    "dim=1：在中间插入新维度，结果形状为 [2, 4, 3]。\n",
    "dim=2：在最后插入新维度，结果形状为 [2, 3, 4]。\n",
    "'''"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:31:37.785723Z",
     "start_time": "2025-05-30T02:31:37.781383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  #shape    [2,3]\n",
    "\n",
    "# 在第0维（新维度）上堆叠4个x\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) #[4,2,3]\n",
    "\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)\n",
    "# 输出:"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:32:08.128886Z",
     "start_time": "2025-05-30T02:32:08.124880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3],\n",
      "         [1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6],\n",
      "         [4, 5, 6]]]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:33:05.217112Z",
     "start_time": "2025-05-30T02:33:05.213467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=2)\n",
    "print(\"堆叠后的张量:\")\n",
    "print(x_stacked, x_stacked.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠后的张量:\n",
      "tensor([[[1, 1, 1, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[4, 4, 4, 4],\n",
      "         [5, 5, 5, 5],\n",
      "         [6, 6, 6, 6]]]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hstack, Vstack 水平/竖直堆叠"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:39:48.490582Z",
     "start_time": "2025-05-30T02:39:48.483873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "b = torch.tensor([[7, 8, 9],\n",
    "                  [10, 11, 12]])  # 形状: [2, 3]\n",
    "\n",
    "hstacked = torch.hstack([a, b])   # 等价于 torch.cat([a, b], dim=1)\n",
    "hstacked, hstacked.shape         #[2,3+3] 水平堆，横着的数字多"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  7,  8,  9],\n",
       "         [ 4,  5,  6, 10, 11, 12]]),\n",
       " torch.Size([2, 6]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:41:28.583407Z",
     "start_time": "2025-05-30T02:41:28.578887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vstacked = torch.vstack([a, b]) #等价于torch.cat([a, b], dim=0)\n",
    "vstacked, vstacked.shape       #[2+2,3] 竖直堆，纵向的[]多"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "与 stack 的对比 <br>\n",
    "hstack/vstack：在现有维度上拼接，不增加新维度。<br>\n",
    "torch.stack()：在新维度上堆叠，增加维度数"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Squeeze 压缩"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:51:43.567014Z",
     "start_time": "2025-05-30T02:51:43.561635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.squeeze() - 去除张量的所有1维\n",
    "x = torch.randn(1,3,1,224,224)  #形状[1, 3, 1, 224, 224]\n",
    "x_squeezed = torch.squeeze(x)\n",
    "x_squeezed.shape    #torch.Size([3, 224, 224])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:54:00.674213Z",
     "start_time": "2025-05-30T02:54:00.669785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [1, 5] 的张量\n",
    "y = torch.randn(1, 5)  # 形状: [1, 5]\n",
    "\n",
    "# 仅移除第0维（大小为1）\n",
    "y_squeezed_0 = torch.squeeze(y, dim=0)  # 形状: [5]\n",
    "\n",
    "# 尝试移除第1维（大小为5不是1，不移除）\n",
    "y_squeezed_1 = torch.squeeze(y, dim=1)  # 形状: [1, 5]（不变）\n",
    "\n",
    "print(\"移除第0维:\", y_squeezed_0.shape)  # 输出: torch.Size([5])\n",
    "print(\"移除第1维:\", y_squeezed_1.shape)  # 输出: torch.Size([1, 5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除第0维: torch.Size([5])\n",
      "移除第1维: torch.Size([1, 5])\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Previous shape: torch.Size([9, 1])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "execution_count": 74,
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "#remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\"\n",
    "      f\"\\nNew shape: {x_squeezed.shape}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unsqueeze 扩展"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T02:56:34.627143Z",
     "start_time": "2025-05-30T02:56:34.623552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [3, 4] 的张量\n",
    "x = torch.randn(3, 4)  # 形状: [3, 4]\n",
    "\n",
    "# 在第0维前插入一个维度   dim0放1\n",
    "x_unsqueezed_0 = torch.unsqueeze(x, dim=0)  # 形状: [1, 3, 4]\n",
    "\n",
    "# 在第1维前插入一个维度\n",
    "x_unsqueezed_1 = torch.unsqueeze(x, dim=1)  # 形状: [3, 1, 4]\n",
    "\n",
    "# 在最后一维后插入一个维度（等价于 dim=2）\n",
    "x_unsqueezed_2 = torch.unsqueeze(x, dim=-1)  # 形状: [3, 4, 1]\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([3, 4])\n",
    "print(\"插入第0维:\", x_unsqueezed_0.shape)  # 输出: torch.Size([1, 3, 4])\n",
    "print(\"插入第1维:\", x_unsqueezed_1.shape)  # 输出: torch.Size([3, 1, 4])\n",
    "print(\"插入最后一维:\", x_unsqueezed_2.shape)  # 输出: torch.Size([3, 4, 1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([3, 4])\n",
      "插入第0维: torch.Size([1, 3, 4])\n",
      "插入第1维: torch.Size([3, 1, 4])\n",
      "插入最后一维: torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:10:00.934197Z",
     "start_time": "2025-05-30T03:10:00.929438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "#加上1维\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:09:07.601684Z",
     "start_time": "2025-05-30T03:09:07.596784Z"
    }
   },
   "cell_type": "code",
   "source": "x_reshaped.squeeze()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Permute 重新排序维度, 也是一种视图，共享内存\n",
    "示例 1：二维矩阵转置（等价于 transpose）"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:20:33.644078Z",
     "start_time": "2025-05-30T03:20:33.639552Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # 创建一个2x3的矩阵\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状: [2, 3]\n",
    "\n",
    "# 使用 permute 实现转置（交换维度0和1）  [3,2]\n",
    "x_permuted = torch.permute(x, (1, 0))  # 等价于 x.transpose(0, 1)\n",
    "\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([2, 3])\n",
    "print(\"转置后形状:\", x_permuted.shape)  # 输出: torch.Size([3, 2])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3])\n",
      "转置后形状: torch.Size([3, 2])\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "示例 2：三维张量维度重排"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:23:06.644309Z",
     "start_time": "2025-05-30T03:23:06.640502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个形状为 [2, 3, 4] 的三维张量\n",
    "x = torch.randn(2, 3, 4)  # 形状: [2, 3, 4]\n",
    "\n",
    "# 重新排列维度为                    [4, 2, 3]\n",
    "x_permuted = torch.permute(x, (2, 0, 1))\n",
    "print(\"原始形状:\", x.shape)  # 输出: torch.Size([2, 3, 4])\n",
    "print(\"重排后形状:\", x_permuted.shape)  # 输出: torch.Size([4, 2, 3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3, 4])\n",
      "重排后形状: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:00:31.183772Z",
     "start_time": "2025-05-30T04:00:31.179811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#图像数据\n",
    "x_original = torch.rand(size = (224,224,3))   #高度，宽度，颜色通道\n",
    "\n",
    "#Permute the original tensor to 重排维度\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:00:39.050090Z",
     "start_time": "2025-05-30T04:00:39.045983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "                              #torch.Size([224, 224, 3])\n",
    "x_original[0,0,0]         #等价于x_original[0][0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1691)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:03:51.074504Z",
     "start_time": "2025-05-30T04:03:51.068118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_original[0,0,0]  = 72818\n",
    "x_original[0,0,0], x_permuted[0,0,0]    #也被改了，因为也是view"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(72818.), tensor(72818.))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## indexing (selecting data from tensors)\n",
    "Indexing with PyTorch is similar to indexing with Numpy"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:05:00.380327Z",
     "start_time": "2025-05-30T06:05:00.375264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create a tensor\n",
    "import torch\n",
    "x = torch.arange(1,10).reshape(1,3,3)  #9个值 1*3*3\n",
    "x, x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:27:09.398516Z",
     "start_time": "2025-05-30T06:27:09.393791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on our new tensor\n",
    "x[0], x[0].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:03:59.840501Z",
     "start_time": "2025-05-30T05:03:59.836959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on the middle bracket (dim=1)  [1, 3, 3]的3行\n",
    "x[0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:10:34.161254Z",
     "start_time": "2025-05-30T05:10:34.157413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets index on the most inner bracket (last dimension)\n",
    "x[0][2][2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:21:06.614949Z",
     "start_time": "2025-05-30T05:21:06.610759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You can also \":\" to select \"all\" of a target dimension\n",
    "'''\n",
    "第0维  dim0\n",
    "\n",
    "[1,3,3]\n",
    "第0维 1   [[]]\n",
    "第1维 3    []\n",
    "第2维 3\n",
    "\n",
    "                ([[[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]]])\n",
    "x[:, 0]\n",
    ":   第0维中所有元素       [[]]               ---从这里开始算上[]\n",
    "0   第1维中index 0的     index0的[1,2,3]\n",
    "                合体后结果:  [[1,2,3]]\n",
    "'''\n",
    "x[:,0],x[:,0].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:05:10.295146Z",
     "start_time": "2025-05-30T06:05:10.291119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#获取所有0维和1维的值，但只获取2维的index1\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "        :  [[]]            ---从这里开始算上[]\n",
    "        :   []内            -- 也要\n",
    "        1   index1的数   2,5,8\n",
    "\n",
    "    结果    [[2,5,8]]\n",
    "\n",
    "x[:,:,数]情况下 --  每个:都要算上[]\n",
    "'''\n",
    "x[:,:,1], x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 5, 8]]), torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:22:12.197064Z",
     "start_time": "2025-05-30T06:22:12.192015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取dim0的所有值，但只获取1维和2维的index1\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "\n",
    "          dim0   [[]]                --不算\n",
    "          dim1   index1 [4,5,6]内的   --开始算上[]\n",
    "          dim2  index1  5\n",
    "\n",
    "          [5]\n",
    "\n",
    "x[:,数,数]，以这第一个数的维度开始算上[]\n",
    "'''\n",
    "x[:,1,1]        #tensor([5])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:29:16.808981Z",
     "start_time": "2025-05-30T06:29:16.803361Z"
    }
   },
   "cell_type": "code",
   "source": "x[0,1,1] #这个没有:就很简单  纯数字 tensor(5)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:32:50.331158Z",
     "start_time": "2025-05-30T06:32:50.326726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取dim0和dim1的index0,和dim2的所有值\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "          shape [1, 3, 3]\n",
    "          dim0 [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]]\n",
    "         dim1   [1,2,3]     --开始算上[]\n",
    "         dim2   所有数字1,2,3\n",
    "\n",
    "         [1,2,3]\n",
    "\n",
    "x[数,数,:]，以第二个数开始算上方括号\n",
    "从内开始合体\n",
    "'''\n",
    "x[0,0,:]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:11.992852Z",
     "start_time": "2025-05-30T06:41:11.988410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# index on x to return 9 #单个数字简单\n",
    "print(x[0,2,2])\n",
    "\n",
    "'''\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "        shape [1, 3, 3]\n",
    "\n",
    "        dim0   [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]]\n",
    "        dim1  :   []         --开始算上[]\n",
    "        dim2  2  index2的数3,6,9\n",
    "\n",
    "\n",
    "[数,:,数] - 从:才开始算上方括号\n",
    "[3,6,9]\n",
    "'''\n",
    "#index on x to return 3,6,9  #多个数字不简单，一列的\n",
    "print(x[0,:,2])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([3, 6, 9])\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:51:14.045823Z",
     "start_time": "2025-05-30T06:51:14.041740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "法二\n",
    "        [[[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]]\n",
    "\n",
    "        shape [1, 3, 3]\n",
    "\n",
    "        dim0  :  [[]]内\n",
    "        dim1  :   []内\n",
    "        dim2  2  index2的数\n",
    "        [[3,6,9]]\n",
    "'''\n",
    "print(x[:,:,2])  #"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pytorch tensors & Numpy\n",
    "\n",
    "Numpy is a popular scientific python numerical computation library.\n",
    "And because of this, pytorch has functionality to interact it.\n",
    "\n",
    "* numpy 转 pytorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* pytorch tensor 转 numpy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:56:57.245322Z",
     "start_time": "2025-05-30T06:56:57.238171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)  #转成了张量，转过来是float64\n",
    "array, tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:57:25.309976Z",
     "start_time": "2025-05-30T06:57:25.305601Z"
    }
   },
   "cell_type": "code",
   "source": "array.dtype  #默认是64位浮点数",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:57:58.157771Z",
     "start_time": "2025-05-30T06:57:58.153647Z"
    }
   },
   "cell_type": "code",
   "source": "torch.arange(1.0, 8.0).dtype    #默认是32位浮点数",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:58:46.270624Z",
     "start_time": "2025-05-30T06:58:46.266909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor.dtype"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:05:07.394327Z",
     "start_time": "2025-05-30T07:05:07.389337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 改array的值，张量没有变化\n",
    "array = array + 1\n",
    "array,tensor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:05:55.394219Z",
     "start_time": "2025-05-30T07:05:55.389020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_array = tensor.numpy()\n",
    "tensor, numpy_array  #默认32位"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:06:31.879599Z",
     "start_time": "2025-05-30T07:06:31.874182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 改tensor， numpy_array不会被改变\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_array"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reproducity 可重现性 - 试图消除随机性\n",
    "神经网络学习从随机数开始-tensor operations-update随机数让他们不断更好地呈现-重复重复...\n",
    "\n",
    "为了减少随机性，有个**random seed**的概念，随机种子作用是调整随机性 flavor\n",
    "\n",
    "pseudorandomness 伪随机 p不发音"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:24:05.892615Z",
     "start_time": "2025-05-30T07:24:05.888141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "#create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)  #不太可能相等"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1150, 0.5938, 0.4360, 0.7190],\n",
      "        [0.9644, 0.3459, 0.2730, 0.5255],\n",
      "        [0.6108, 0.6793, 0.1615, 0.4528]])\n",
      "tensor([[0.3452, 0.0106, 0.7481, 0.9619],\n",
      "        [0.4960, 0.7634, 0.7174, 0.0300],\n",
      "        [0.0459, 0.8586, 0.3811, 0.6978]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:29:17.438949Z",
     "start_time": "2025-05-30T07:29:17.432565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 让我们做些随机但可重现的张量\n",
    "import torch\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42 #默认是42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)  #每次随机前都要设置下\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Running tensors and pytorch objects on GPUs and 计算地更快\n",
    "\n",
    "GPUs = 更快的数字计算  因为CUDA, NVIDIA,和pytorch背后计算"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "选项\n",
    "1. google Colab\n",
    "2. 自己的GPU\n",
    "3. cloud computing - GCP, AWS, Azure"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check for GPU access with pytorch"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:53:54.313553Z",
     "start_time": "2025-05-30T07:53:52.732712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for GPU access with pytorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:54:49.518921Z",
     "start_time": "2025-05-30T07:54:49.515084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup device agnostic code 设备无关性\n",
    "# 自动选择可用的计算设备（GPU 或 CPU）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:56:42.847407Z",
     "start_time": "2025-05-30T07:56:42.843608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count number of devices\n",
    "torch.cuda.device_count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Putting tensors and models on the GPU\n",
    "\n",
    "The reason we want to put on GPU 因为他快"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:00:27.236661Z",
     "start_time": "2025-05-30T08:00:27.232777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1,2,3],device=\"cpu\")\n",
    "\n",
    "#不在gpu上\n",
    "print(tensor, tensor.device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:01:18.445913Z",
     "start_time": "2025-05-30T08:01:16.792277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.Moving tensors back to CPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:03:41.211491Z",
     "start_time": "2025-05-30T08:03:41.208961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if tensor is on GPU, 不能转换成numpy\n",
    "# tensor_on_gpu.numpy() 会报错！"
   ],
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:04:31.686085Z",
     "start_time": "2025-05-30T08:04:31.680492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 解决方法 - 设置一个在cpu上的\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:04:54.614798Z",
     "start_time": "2025-05-30T08:04:54.609724Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_on_gpu #还是在gpu上面",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise & Extracurriculars\n",
    "作业: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb <br>\n",
    "答案：https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "THE END\n",
    "<hr>"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:49:01.864239Z",
     "start_time": "2025-05-30T09:49:01.861693Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
